{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the required libraries\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating weights for all items\n",
    "#weights is a dictionary, keys->items, values-> weights\n",
    "weights=dict()\n",
    "for i in range(500):\n",
    "    weights[i]=random.uniform(0,2) #weight is a random value between 0 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating prices for all items\n",
    "#prices is a dictionary, keys-> items, values->prices\n",
    "prices=dict()\n",
    "for i in range(500):\n",
    "    prices[i]=random.randint(100,1000)#Since we are generating carts ourselves we have generated prices randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the data in pickle files to maintain uniformity across different implementations\n",
    "file_weights = 'weights'\n",
    "outfile1 = open(file_weights,'wb')\n",
    "pickle.dump(weights,outfile1)\n",
    "outfile1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the data in pickle files to maintain uniformity across different implementations\n",
    "file_prices = 'prices'\n",
    "outfile2 = open(file_prices,'wb')\n",
    "pickle.dump(prices,outfile2)\n",
    "outfile2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating 1000 carts for 10 experiments with 500 products\n",
    "carts=dict()\n",
    "for experiment in range(10):\n",
    "    current_carts=[]\n",
    "    for cart in range(1000):\n",
    "        new_cart=[]\n",
    "        for product in range(500):\n",
    "            prob=random.uniform(0,1)\n",
    "            if(prob<=0.02):\n",
    "                new_cart.append(product)\n",
    "        current_carts.append(new_cart)\n",
    "    carts[experiment]=current_carts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the data in pickle files to maintain uniformity across different implementations\n",
    "file_carts = 'carts'\n",
    "outfile3 = open(file_carts,'wb')\n",
    "pickle.dump(carts,outfile3)\n",
    "outfile3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the amazon co-purchasing data. Since the amazon data has very large no. of nodes we have filtered it\n",
    "#to consider only 500 nodes\n",
    "#The data is in the form of edge lists\n",
    "amazon_500=[]\n",
    "file = open(\"amazon.txt\")\n",
    "for line in file.readlines():\n",
    "    if(line[0]=='#'):\n",
    "        continue\n",
    "    else:\n",
    "        line=line.rstrip(\"\\n\")\n",
    "        line=line.split(\"\\t\")\n",
    "        from_node=int(line[0])\n",
    "        to_node=int(line[1])\n",
    "        if(from_node>=500):\n",
    "            break\n",
    "        if(to_node<500):\n",
    "            amazon_500.append((from_node,to_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BFS Traversal of a network\n",
    "#Inputs-> source node, total no. of nodes, adjacency list dictionar y of a network\n",
    "#BFS follow a FIFO traversal.\n",
    "#This method returns a list. index-> Node no. Value-> Shortest dist ance between node and source node\n",
    "def bfs(s,n,adj_list):\n",
    "    \n",
    "    visited = [False] * (n) #Visited stores the status of each node. Initially all nodes are unvisited\n",
    "    temp_list=dict()#Stores the distance of all the nodes from the source node \n",
    "    queue = [] #BFS uses a queue data structure. Queue follows the FIFO property\n",
    "    queue.append(s)\n",
    "    visited[s] = True\n",
    "    temp_list[s]=0\n",
    "    while queue:\n",
    "            # Dequeue a vertex from the queue.This node becomes the current node\n",
    "        node = queue.pop(0)\n",
    "            #Now we need to visit all the unvisited neighbouring nodes of the current node\n",
    "            #distance of these unvisited neighbouring nodes would be distance of current_node+1\n",
    "        for i in adj_list[node]:\n",
    "            \n",
    "            if visited[i] == False:\n",
    "                queue.append(i)\n",
    "                visited[i] = True\n",
    "                temp_list[i]=temp_list[node]+1\n",
    "                \n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average Path Length/Characteristic Path Length\n",
    "#Path Length= Length of shortest path between 2 nodes.\n",
    "#BFS returns the shortest path between 2 nodes\n",
    "#Avg Path Length= sum(shortest path length between all unique pairs )/no. of unique pairs\n",
    "#No. of unique pairs=(no. of nodes * no. of nodes-1)/2\n",
    "#This method takes the adj list dictionary of the network as input #This method returns the characteristic path length of the network\n",
    "def avg_path_length(n,adj_list):\n",
    "    distance_list=[]\n",
    "    for s in range(n):  #Calling bfs by considering each node as a source node\n",
    "        temp_list=bfs(s,n,adj_list)\n",
    "    distance_list.append(temp_list)\n",
    "    avg_path_length=0\n",
    "    #Summing up the distances between all the node pairs\n",
    "    for curr_dict in distance_list:\n",
    "        for distances in curr_dict.values():\n",
    "            avg_path_length+=distances\n",
    "    avg_path_length=avg_path_length/2 #Need to count distance between any 2 nodes only once\n",
    "    avg_path_length=2*avg_path_length/(n*(n-1))\n",
    "    return avg_path_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the amazon edge list to adjacency list\n",
    "adj_list_amazon=dict()\n",
    "for i in range(500):\n",
    "    adj_list_amazon[i]=[]\n",
    "for edge in amazon_500:\n",
    "    node1=edge[0]\n",
    "    node2=edge[1]\n",
    "    if(node2 not in adj_list_amazon[node1]):\n",
    "        adj_list_amazon[node1].append(node2)\n",
    "    if(node1 not in adj_list_amazon[node2]):\n",
    "        adj_list_amazon[node2].append(node1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009322645290581162\n"
     ]
    }
   ],
   "source": [
    "#Calculating average path length for amazon co-purchasing data\n",
    "avg_path_length_amazon=avg_path_length(500,adj_list_amazon)\n",
    "print(avg_path_length_amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#Creating an empty list of dicts\n",
    "#Index of the list represents experiment no.\n",
    "#Value is an empty dict representing the adj list\n",
    "#key->product no\n",
    "#value->empty list to hold the neighbours\n",
    "list_of_adj_lists=[]\n",
    "for experiment in range(10):\n",
    "    print(experiment)   \n",
    "    adj_list=dict()\n",
    "    for product in range(500):\n",
    "        adj_list[product]=[]\n",
    "    list_of_adj_lists.append(adj_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the avg path lengths for all the 10 experiments\n",
    "#Updating the list_of_adj_lists to hold actual adj list which are generated from the carts\n",
    "avg_path_length_list=[]\n",
    "for experiment in range(10):\n",
    "    adj_list=list_of_adj_lists[experiment]\n",
    "    cart_lists=carts[experiment]\n",
    "    for cart in cart_lists:\n",
    "        for i in range(len(cart)-1):\n",
    "            for j in range(i+1,len(cart),1):\n",
    "                if(cart[j] not in adj_list[cart[i]]):\n",
    "                    adj_list[cart[i]].append(cart[j])\n",
    "                if(cart[i] not in adj_list[cart[j]]):\n",
    "                    adj_list[cart[j]].append(cart[i])\n",
    "    avg_path_length_list.append((avg_path_length(500,adj_list)))\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0033414829659318634\n"
     ]
    }
   ],
   "source": [
    "#Average path length across all the 10 experiments\n",
    "print(sum(avg_path_length_list)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the neighbours list in all adj lists\n",
    "for experiment in range(10):\n",
    "    adj_list=list_of_adj_lists[experiment]\n",
    "    for product in range(500):\n",
    "        adj_list[product].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the data in pickle files to maintain uniformity across different implementations\n",
    "file_adj_list = 'adj_list'\n",
    "outfile6 = open(file_adj_list,'wb')\n",
    "pickle.dump(list_of_adj_lists,outfile6)\n",
    "outfile6.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating f and g\n",
    "# f represents the frequency score of an item\n",
    "# g represents the frequecy score of 2 items purchased together\n",
    "#initializing f and g's to 0\n",
    "f=[]\n",
    "g=[]\n",
    "for experiment in range(10):\n",
    "    temp_dict=dict()\n",
    "    for product in range(500):\n",
    "        temp_dict[product]=0\n",
    "    f.append(temp_dict)\n",
    "for experiment in range(10):\n",
    "    temp_dict_g=dict()\n",
    "    for product1 in range(499):\n",
    "        for product2 in range(product1,500,1):\n",
    "            temp_dict_g[(product1,product2)]=0\n",
    "    g.append(temp_dict_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the values of f and g\n",
    "for experiment in range(10):\n",
    "    carts_list=carts[experiment]\n",
    "    for cart in carts_list:\n",
    "        if(len(cart)==1):\n",
    "            f[experiment][cart[0]]+=1\n",
    "        else:\n",
    "            k=len(cart)\n",
    "            for i in range(len(cart)-1):\n",
    "                current_product=cart[i]\n",
    "                f[experiment][current_product]+=(1/k)\n",
    "                for j in range(i+1,len(cart),1):\n",
    "                    copurchase_product=cart[j]\n",
    "                    g[experiment][(current_product,copurchase_product)]+=(1/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the data in pickle files to maintain uniformity across different implementations\n",
    "file_f = 'f'\n",
    "outfile4 = open(file_f,'wb')\n",
    "pickle.dump(f,outfile4)\n",
    "outfile4.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the data in pickle files to maintain uniformity across different implementations\n",
    "file_g = 'g'\n",
    "outfile5 = open(file_g,'wb')\n",
    "pickle.dump(g,outfile5)\n",
    "outfile5.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
